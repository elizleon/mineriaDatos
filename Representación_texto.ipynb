{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizleon/mineriaDatos/blob/main/Representaci%C3%B3n_texto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Universidad Nacional de Colombia\n",
        "##Minería de Datos - PLN\n",
        "\n",
        "## Prof. Elizabeth León\n",
        "## **Ejercicio Transformación de texto y extracción de características**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "KFOYNJIVGeDr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDMDzRwvF509"
      },
      "source": [
        "# Representación de texto y extracción de características\n",
        "\n",
        "Para analizar documento textuales es necesario transformar el texto a números, ya que muchos de los algoritmos de minería de datos trabajan con representaciones numéricas. Es necesario realizar preprocesamiento al texto para eliminar ruido, ambigüedad y reducir la dimensionalidad. Se necesita aplicar el proceso de extracción de características (*feature extraction*) para representar el texto en vectores numéricos que codifican características significativas en el texto.\n",
        "\n",
        "En la presente sesión trataremos varios métodos para extracción de características desde los tradicionales basados en extracción de características manuales como Bolsa de palabras (Bag of Words - BoW) hasta aquellos basados en deep learning (Word2Vec)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30SRDeOBTHjW"
      },
      "source": [
        "## Construyendo un text corpus\n",
        "\n",
        "Construiremos un text corpus sencillo sobre el cual demostraremos las diferentes metodologías y modelos de extracción de características."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKqDXtm_YbV_"
      },
      "source": [
        "# Importamos las librerías básicas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.max_colwidth = 200\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW2fE07ecux6",
        "outputId": "3e46249e-fd66-4529-cb51-6916d677b423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        }
      },
      "source": [
        "# Popular corpus and classes\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg9BoGUsY5qC"
      },
      "source": [
        "# Definimos un corpus de prueba sencillo\n",
        "corpus = ['The sky is blue and beautiful.',\n",
        "'Love this blue and beautiful sky!',\n",
        "'The quick brown fox jumps over the lazy dog.',\n",
        "\"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "'I love green eggs, ham, sausages and bacon!',\n",
        "'The brown fox is quick and the blue dog is lazy!',\n",
        "'The sky is very blue and the sky is very beautiful today',\n",
        "'The dog is lazy but the brown fox is quick!'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fs2Zpn0ZtwE"
      },
      "source": [
        "# Asignamos un label para cada oración\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD_vAEP8Z-kL",
        "outputId": "9fd121cf-b56c-4b44-8d2b-1ef006bb09f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# Convertimos el corpus a un Pandas dataframe\n",
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({\"Document\": corpus, \"Category\": labels})\n",
        "corpus_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document Category\n",
              "0                                      The sky is blue and beautiful.  weather\n",
              "1                                   Love this blue and beautiful sky!  weather\n",
              "2                        The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
              "4                         I love green eggs, ham, sausages and bacon!     food\n",
              "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
              "6            The sky is very blue and the sky is very beautiful today  weather\n",
              "7                         The dog is lazy but the brown fox is quick!  animals"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kJoaiwZaiKp"
      },
      "source": [
        "#### Preprocesamiento\n",
        "\n",
        "Antes de extraer características debemos preprocesar el texto, eliminado los caracteres innecesarios, los signos de puntuación, los stop words, tokenizar, etc.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdT0Iz0bcUN3"
      },
      "source": [
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "def normalize_document(doc):\n",
        "  # lowercase and remove special characters\\whitespace\n",
        "  doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "  doc = doc.lower()\n",
        "  doc = doc.strip()\n",
        "  # tokenize document\n",
        "  tokens = wpt.tokenize(doc)\n",
        "  # filter stopwords out of document\n",
        "  filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "  # re-create document from filtered tokens\n",
        "  doc = ' '.join(filtered_tokens)\n",
        "  return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shIAcLNgd5HR"
      },
      "source": [
        "# Vectorizamos la función de extracción de características\n",
        "normalize_corpus = np.vectorize(normalize_document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyxxJnK7ethV",
        "outputId": "89b761eb-2343-4c54-ce22-868c60aa4279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "# Normalizamos el corpus\n",
        "norm_corpus = normalize_corpus(corpus)\n",
        "norm_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0e0l2vGfCYC"
      },
      "source": [
        "Con el corpus preprocesado procedemos a aplicar los diferentes extractores de características."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fF-0xtjRDwa"
      },
      "source": [
        "## Bolsa de Palabras - Bag of Words (Bow)\n",
        "\n",
        "Es el modelo de representación vectorial más simple, representa cada documentos en el corpus como un vector numérico donde cada dimensión es una palabra especifica en el corpus y el valor puede ser un conteo de frecuencia de la palabra en el documento, la ocurrencia o no de la palabra en el documento (0 si la palabra no se encuentra en el documento; 1 en otro caso), incluso pueden ser valores de pesados.\n",
        "\n",
        "Este modelo no toma en cuenta la secuencia de palabras, gramática o semántica.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tltpQ3ZnfPN9"
      },
      "source": [
        "# Importamos el extractor de características BoW de Scikit-learn\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chz7YaVZFp7A",
        "outputId": "05c92bdc-0152-41bd-d24f-51432313c00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Instanciamos el extractor de características para la ocurrencia de palabras\n",
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "# Extraemos las características del corpus\n",
        "cv_matrix = cv.fit_transform(norm_corpus)\n",
        "# El resultado es una matriz sparse\n",
        "cv_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8x20 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 42 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhSEXDLGkl-1",
        "outputId": "aa5db0fc-23d1-4f2c-b751-f540c5866b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "# Visualizamos las carcterísticas distintas de zero\n",
        "print(cv_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 17)\t1\n",
            "  (0, 3)\t1\n",
            "  (0, 2)\t1\n",
            "  (1, 17)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 2)\t1\n",
            "  (1, 14)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 5)\t1\n",
            "  (2, 8)\t1\n",
            "  (2, 11)\t1\n",
            "  (2, 13)\t1\n",
            "  (2, 6)\t1\n",
            "  (3, 12)\t1\n",
            "  (3, 4)\t1\n",
            "  (3, 16)\t1\n",
            "  (3, 10)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 7)\t1\n",
            "  (3, 18)\t1\n",
            "  (3, 1)\t1\n",
            "  (4, 14)\t1\n",
            "  (4, 16)\t1\n",
            "  (4, 10)\t1\n",
            "  (4, 0)\t1\n",
            "  (4, 7)\t1\n",
            "  (4, 9)\t1\n",
            "  (5, 3)\t1\n",
            "  (5, 15)\t1\n",
            "  (5, 5)\t1\n",
            "  (5, 8)\t1\n",
            "  (5, 13)\t1\n",
            "  (5, 6)\t1\n",
            "  (6, 17)\t2\n",
            "  (6, 3)\t1\n",
            "  (6, 2)\t1\n",
            "  (6, 19)\t1\n",
            "  (7, 15)\t1\n",
            "  (7, 5)\t1\n",
            "  (7, 8)\t1\n",
            "  (7, 13)\t1\n",
            "  (7, 6)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcD1YhLIlCU5"
      },
      "source": [
        "El resultado es una matriz sparse porque el número de palabras puede incrementarse de manera exponencial con cada nuevo documento, pues cada palabra distinta se convierte en una nueva característica. El resultado previo muestra los pares (**x**,**y**) de la matriz de características que son distintos de cero, donde **x** representa a un documento y **y** representa un termino en el corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwwF1f6nk0X4",
        "outputId": "aae16c2a-5c6f-4930-b8a4-2081220fbfa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# Convertimos de la representación sparse a la densa para visualizarla como numpy array\n",
        "cv_matrix = cv_matrix.toarray()\n",
        "cv_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wVcSqyinM0S"
      },
      "source": [
        "Como podemos observar cada documento es representado como una fila y cada columna representa una palabra en el corpus. Podemos visualizarlo mejor usando un pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNDRhqOsji5i",
        "outputId": "3b1cb1d0-21d1-4078-e672-ed40b16c0a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# Obtenemos todas las palabras diferentes en el corpus\n",
        "vocab = cv.get_feature_names()\n",
        "# Mostramos el documento y las features\n",
        "pd.DataFrame(cv_matrix, columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  breakfast  ...  quick  sausages  sky  toast  today\n",
              "0      0      0          1     1          0  ...      0         0    1      0      0\n",
              "1      0      0          1     1          0  ...      0         0    1      0      0\n",
              "2      0      0          0     0          0  ...      1         0    0      0      0\n",
              "3      1      1          0     0          1  ...      0         1    0      1      0\n",
              "4      1      0          0     0          0  ...      0         1    0      0      0\n",
              "5      0      0          0     1          0  ...      1         0    0      0      0\n",
              "6      0      0          1     1          0  ...      0         0    2      0      1\n",
              "7      0      0          0     0          0  ...      1         0    0      0      0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdLpMNUcj-pU"
      },
      "source": [
        "Se puede ver claramente que cada columna o dimensión representa una palabra en el corpus y cada fila representa un documento. Cada celda representa el número de veces que una palabra (columna) aparece en un documento (fila)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMD7Fmq4ksSW"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "El modelo BoW tiene algunos limitantes cuando se aplica a grandes corpus de documentos. Por ejemplo puede darse el caso que un término se repita de manera común en muchos de los documentos del corpus, estos términos comunes tienden a opacar términos que son más representativos de una clase o documento. Para solventar esta limitación surge TF-IDF que significa **term frequency-inverse document frequency**, esto es la combinación de dos medidas, la frecuencia del término (tf) y la inversa de la frecuencia del documento (idf). Este modelo fue originalmente propuesto como métrica para la evaluación de resultados en motores de búsqueda y se convirtió en un estándar dentro de los sistemas de extracción de características para recuperación de información.\n",
        "\n",
        "Formalmente podemos definir tf-idf como sigue:\n",
        "$$tfidf=tf \\times idf$$\n",
        "Es decir tf-idf es el producto del valor tf y el valor idf. El valor tf se puede definir como:\n",
        "$$tf(w,D) = f_{w_D}$$\n",
        "Donde $f_{w_D}$ denota la frecuencia de la palabra **w** en el documento **D**, esto es la frecuencia del término (tf). En algunas ocasiones también se puede normalizar esta frecuencia utilizando logaritmos o promedios de frecuencia, sin embargo nosotros utilizaremos la frecuencia absoluta en nuestros cálculos.\n",
        "\n",
        "*Inverse document frequency* (idf) es la inversa de la frecuencia de los documentos y la obtenemos dividiendo el número total de documentos en el corpus entre el número de documentos que contienen el término **w** (frecuencia de documento) y luego aplicamos un escalado logarítmico al resultado. Adicionalmente sumamos 1 a la frecuencia de documento para evitar errores e indeterminaciones provenientes de la división por 0. También sumamos 1 al idf para tomar en cuenta aquellos términos que podrían tener un idf de cero. Matemáticamente la implementación de idf es:\n",
        "$$idf(w,D)=1+log \\frac{N}{1+df(w)}$$\n",
        "donde $idf(w,D)$ representa la idf para el término o palabra **w** en el documento **D**, **N** representa el total de documentos en el corpus, y $df(w)$ representa el número de documentos que contienen el término **w**.\n",
        "\n",
        "Finalmente también podemos normalizar el vector tf-idf dividiéndolo por su norma euclidiana ($L_2$), podemos representar este proceso como sigue:\n",
        "$$tfidf=\\frac{tfidf}{||tfidf||}$$\n",
        "donde $||tfidf||$ representa la norma euclidiana ($L_2$) de la matriz tf-idf. Existen múltiples variantes de este modelo pero todas terminan con resultados similares. Vamos a aplicar este modelo a nuestro corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql5RsD-nuIws"
      },
      "source": [
        "# Importamos el extractor de características tf-idf de scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnE7widGuWqq"
      },
      "source": [
        "# Creamos el objeto tf-idf transformer y extraemos las características del corpus\n",
        "tt = TfidfTransformer(norm=\"l2\", use_idf=True)\n",
        "# Obtenemos la matrix tf-idf del modelo BoW\n",
        "tt_matrix = tt.fit_transform(cv_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcTo9sLvvSwR",
        "outputId": "70d4c4da-514f-47ea-95f7-9948d2285497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# Visualizamos la matrix tf-idf\n",
        "tt_matrix = tt_matrix.toarray()\n",
        "vocab = cv.get_feature_names()\n",
        "pd.DataFrame(np.round(tt_matrix, 2), columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  ...  sausages   sky  toast  today\n",
              "0   0.00   0.00       0.60  0.53  ...      0.00  0.60   0.00    0.0\n",
              "1   0.00   0.00       0.49  0.43  ...      0.00  0.49   0.00    0.0\n",
              "2   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "3   0.32   0.38       0.00  0.00  ...      0.32  0.00   0.38    0.0\n",
              "4   0.39   0.00       0.00  0.00  ...      0.39  0.00   0.00    0.0\n",
              "5   0.00   0.00       0.00  0.37  ...      0.00  0.00   0.00    0.0\n",
              "6   0.00   0.00       0.36  0.32  ...      0.00  0.72   0.00    0.5\n",
              "7   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9nWcLszvt_c"
      },
      "source": [
        "TfidfTransformer toma como entrada el vector de Bag of Words y lo transforma en su representación tf-idf. No es necesario calcular el modelo BoW antes de obtener la representación tf-idf, con la clase TfidfVectorizer podremos obtener la representación tf-idf directamente del texto como se muestra a continuación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDGpnklkxcLP"
      },
      "source": [
        "# Importamos el extractor de características de scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA8XLTHfxo3B"
      },
      "source": [
        "# Instanciamos la clase\n",
        "tv = TfidfVectorizer(min_df=0., max_df=1., norm=\"l2\", use_idf=True, smooth_idf=True)\n",
        "# Entrenamos y extraemos características\n",
        "tv_matrix= tv.fit_transform(norm_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvDjmKZPyBtO",
        "outputId": "65ab36dc-ea8a-40cd-c29d-1a867e4f7557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "# Visualizamos el resultado tf-idf obtenido\n",
        "tv_matrix= tv_matrix.toarray()\n",
        "vocab = tv.get_feature_names()\n",
        "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  ...  sausages   sky  toast  today\n",
              "0   0.00   0.00       0.60  0.53  ...      0.00  0.60   0.00    0.0\n",
              "1   0.00   0.00       0.49  0.43  ...      0.00  0.49   0.00    0.0\n",
              "2   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "3   0.32   0.38       0.00  0.00  ...      0.32  0.00   0.38    0.0\n",
              "4   0.39   0.00       0.00  0.00  ...      0.39  0.00   0.00    0.0\n",
              "5   0.00   0.00       0.00  0.37  ...      0.00  0.00   0.00    0.0\n",
              "6   0.00   0.00       0.36  0.32  ...      0.00  0.72   0.00    0.5\n",
              "7   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUdjhR4ypYh"
      },
      "source": [
        "## Extracción de características con Word2Vec\n",
        "\n",
        "Los modelos de extracción de características utilizados hasta el momento están basados en conteo y frecuencia pero no toman en cuenta importantes características del texto como son por ejemplo la secuencia, estructura, contexto y significado. Word2vec es un modelo de  *word embedding* creado por Google en 2013, está basado en deep learning y su objetivo es transformar las palabras en vectores numéricos densos dentro de un espacio vectorial continuo que captura la información contextual y semántica.\n",
        "\n",
        "Esencialmente este modelo es no supervisado tomando grandes cantidades de texto, crea un vocabulario de las posibles palabras y genera *dense word embeddings*. Usualmente es posible definir el tamaño de los vectores de *word embedding*. Esto hace que la representación de word embedding sea más compacta que aquella obtenida del modelo BoW que por naturaleza es sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gglzYoJ5Paj"
      },
      "source": [
        "Para entrenar nuestro modelo word2vec necesitamos un corpus mucho más grande por ello usaremos el corpus de la biblia, que importaremos aquí."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsxk6noN2LoR"
      },
      "source": [
        "# Importamos el corpus\n",
        "from nltk.corpus import gutenberg\n",
        "# Importamos módulo para manejar la puntuación\n",
        "from string import punctuation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR6V_iLv5rYv"
      },
      "source": [
        "# Cargamos el corpus\n",
        "bible = gutenberg.sents(\"bible-kjv.txt\")\n",
        "# Definimos los términos a remover\n",
        "remove_terms = punctuation + \"0123456789\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5PK2GFm6P_5",
        "outputId": "8a3c9914-c4e8-41f5-a286-68be51709366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "# Normalizamos el texto\n",
        "norm_bible = [ [word.lower() for word in sent if word not in remove_terms] for sent in bible]\n",
        "norm_bible = [' '.join(tok_sent) for tok_sent in norm_bible]\n",
        "norm_bible = filter(None, normalize_corpus(norm_bible))\n",
        "norm_bible = [tok_sent for tok_sent in norm_bible if len(tok_sent.split()) > 2]\n",
        "# imprimimos el número total de filas, un ejemplo de linea raw y procesada\n",
        "print('Total lines:', len(bible))\n",
        "print('\\nSample line:', bible[10])\n",
        "print('\\nProcessed line:', norm_bible[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total lines: 30103\n",
            "\n",
            "Sample line: ['1', ':', '6', 'And', 'God', 'said', ',', 'Let', 'there', 'be', 'a', 'firmament', 'in', 'the', 'midst', 'of', 'the', 'waters', ',', 'and', 'let', 'it', 'divide', 'the', 'waters', 'from', 'the', 'waters', '.']\n",
            "\n",
            "Processed line: god said let firmament midst waters let divide waters waters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXN9D7TK6wmV"
      },
      "source": [
        "Existen numerosas implementaciones del algoritmo Word2vec sin embargo las más eficientes se encuentran dentro de la librería gemsim usaremos esta implementación para entrenar un modelo de word2vec y extraer características con él."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Nr0PpM7pIi",
        "outputId": "93bea2aa-c909-4988-9f91-432f5e197a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Instalamos el módulo word2vec\n",
        "!pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.153)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.153 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.153)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.153->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.153->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8KRas1t7Wv7"
      },
      "source": [
        "# Importamos word2vec from gemsim\n",
        "from gensim.models import word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqoRPXJl7-yz"
      },
      "source": [
        "# tokenize en oraciones el corpus\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "tokenized_corpus = [wpt.tokenize(document) for document in norm_bible]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Rs3jVA8Lgx"
      },
      "source": [
        "Los siguientes parámetros son utilizados por el modelo Word2vec para construir el modelo:\n",
        "* feature_size: Determina la dimensión de los vectores de embedding\n",
        "* window_context: Es el número de palabras que tomará en cuenta el modelo para construir el contexto\n",
        "* min_word_count: Especifica el conteo mínimo de una palabra dentro del corpus para ser tomada en cuenta dentro del vocabulario\n",
        "* sample: este parámetro es usado para el sub-muestreo dentro del algoritmo. Los valores entre 0.01 entre 0.0001 son usualmente ideales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPawqV9c8GSD"
      },
      "source": [
        "# Set values for various parameters\n",
        "feature_size = 100 # Word vector dimensionality\n",
        "window_context = 30 # Context window size\n",
        "min_word_count = 1 # Minimum word count\n",
        "sample = 1e-3 # Downsample setting for frequent words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWOUdjPo9fkz"
      },
      "source": [
        "# definimos el modelo y lo entrenamos\n",
        "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size,\n",
        "                              window=window_context, min_count=min_word_count,\n",
        "                              sample=sample, iter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIG8AluM9pJC",
        "outputId": "e01a9131-ccfb-4ab0-e9f2-fa8823511340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "# Visualizamos las palabras que son similares de acuerdo al modelo de gensim\n",
        "similar_words = {search_term: [item[0] for item in w2v_model.wv.most_similar([search_term], topn=5)]\n",
        "                 for search_term in ['god', 'jesus', 'noah','egypt', 'john', 'gospel', 'moses','famine']}\n",
        "similar_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'egypt': ['egyptians', 'pharaoh', 'bondage', 'rid', 'rod'],\n",
              " 'famine': ['pestilence', 'peril', 'blasting', 'overtaketh', 'mildew'],\n",
              " 'god': ['lord', 'worldly', 'sworn', 'ever', 'promised'],\n",
              " 'gospel': ['christ', 'faith', 'preach', 'afflictions', 'godly'],\n",
              " 'jesus': ['peter', 'messias', 'apostles', 'cross', 'synagogue'],\n",
              " 'john': ['baptist', 'james', 'devine', 'galilee', 'zebedee'],\n",
              " 'moses': ['congregation', 'children', 'elisheba', 'naashon', 'joshua'],\n",
              " 'noah': ['ham', 'shem', 'japheth', 'kenan', 'enosh']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUcZI1Wl-GIb"
      },
      "source": [
        "Vamos a visualizar las palabras de interés y sus similares usando su presentación de embedding, después de reducir su dimensionalidad a un espacio 2D con t-SNE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKbDL62q-pgw"
      },
      "source": [
        "# Para reducir la dimensionalidad del word embedding\n",
        "from sklearn.manifold import TSNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWy82APU-xih"
      },
      "source": [
        "# Obtenemos las palabras similares\n",
        "words = sum([[k] + v for k, v in similar_words.items()], [])\n",
        "wvs = w2v_model.wv[words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ATK40Ax-5TG"
      },
      "source": [
        "# Reducimos la dimensionalidad\n",
        "tsne = TSNE(n_components=2, random_state=0, n_iter=10000, perplexity=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = tsne.fit_transform(wvs)\n",
        "labels = words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fcatJ00-_F4",
        "outputId": "99ab2e68-8da7-472c-95f9-ec69910ec6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "# Visualizamos\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='orange', edgecolors='r')\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "  plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAAHVCAYAAADRvDvhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j+n8n+KToVgnAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFGlpYEV_OWI"
      },
      "source": [
        "Como podemos observar las palabras similares aparecen cerca en este espacio formando grupos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUUBBPcx_gnT"
      },
      "source": [
        "#### Estrategia para la extracción de características con Word2vec\n",
        "\n",
        "Ahora que hemos entrenado el modelo Word2vec lo podremos utilizar para extraer las características de los documentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DRjIFKvAcWH"
      },
      "source": [
        "Para obtener la representación de una palabra desde el modelo de embedding utilizamos una palabra como clave del diccionario wv dentro del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz-rZkFOBQ5I",
        "outputId": "a8fcefdf-38ae-43be-97a3-7346d51ec2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Obtenemos la representación de word embedding para la palabra sky\n",
        "w2v_model.wv[\"sky\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.13906665, -0.09467818,  0.03351992,  0.27260017,  0.5489181 ,\n",
              "        0.09396461,  0.27909434,  0.02730848, -0.5168682 , -0.74485075,\n",
              "        0.35855186,  0.26168385,  0.40251988,  0.04674069,  0.08227883,\n",
              "        0.06284666,  0.40914953, -0.868972  , -0.46806145, -0.20395283,\n",
              "        0.26269644, -0.16583093,  0.21720047, -1.1470268 ,  0.64572006,\n",
              "        0.2179737 ,  0.57766604, -0.07732975,  0.10162247,  0.35236475,\n",
              "       -0.3371417 ,  0.17316462,  0.3121608 , -0.15885124,  0.5577189 ,\n",
              "       -0.53220177, -0.43150327,  1.1746895 , -0.5024037 ,  0.15712567,\n",
              "       -0.12766321, -0.20109402,  0.43525183, -0.17893094, -0.8144733 ,\n",
              "       -0.79684144,  0.8236569 , -0.2813059 , -0.64945453, -0.22779943,\n",
              "       -0.67609227, -0.24860808,  0.29617646,  0.40474543,  1.1627791 ,\n",
              "       -0.66091585, -0.12663774, -0.6829365 , -0.41497838, -0.23677988,\n",
              "       -0.22100426,  0.7180309 , -0.00584291,  0.3720943 ,  0.40510976,\n",
              "        0.24102566, -0.653215  , -0.67209685, -0.78019905, -0.20582074,\n",
              "       -0.1092019 , -0.1119693 , -0.30541286, -0.2766395 ,  0.23444594,\n",
              "        0.12381047, -0.22674288, -0.36346775,  0.34215885, -0.47185963,\n",
              "       -1.1744652 ,  0.50694203,  0.07966118,  0.2510521 , -0.2673603 ,\n",
              "       -0.24781932,  0.45597804, -0.6724422 ,  0.05680818,  0.0187033 ,\n",
              "        0.9085017 ,  0.45798045, -0.5145227 ,  0.11709376, -0.21737182,\n",
              "        0.62661904,  0.02821464,  0.92149484, -0.5969242 , -0.4156528 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VLCho0oBfji"
      },
      "source": [
        "Debido a que cada documento puede tener un numero distinto de palabras una estrategia muy común para obtener la representación Word2vec a escala de documento es extraer la representación de cada palabra en el documento y promediar estas representaciones dado que todas ellas tienen la misma dimensión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfHaX4qzCYMu"
      },
      "source": [
        "# Función para extraer características a nivel de documento\n",
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "  feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "  nwords = 0.\n",
        "  for word in words:\n",
        "    if word in vocabulary:\n",
        "      nwords = nwords + 1.\n",
        "      feature_vector = np.add(feature_vector, model[word])\n",
        "  if nwords:\n",
        "    feature_vector = np.divide(feature_vector, nwords)\n",
        "  return feature_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kIm0JknCulS"
      },
      "source": [
        "# Función vectorizada para aplicarla al corpus entero\n",
        "def averaged_word_vectorizer(corpus, model, num_features):\n",
        "  vocabulary = set(model.wv.index2word)\n",
        "  features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features) for tokenized_sentence in corpus]\n",
        "  return np.array(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKbFTXk9C_1b",
        "outputId": "1c464cf2-7ae5-494c-dfb6-51230c90e99c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Aplicamos al corpus de la biblia\n",
        "w2v_feature_array = averaged_word_vectorizer(corpus=tokenized_corpus,\n",
        "model=w2v_model, num_features=feature_size)\n",
        "# Visualizamos algunas de las representaciones\n",
        "pd.DataFrame(w2v_feature_array).head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.532842</td>\n",
              "      <td>0.140309</td>\n",
              "      <td>-0.333336</td>\n",
              "      <td>-0.784747</td>\n",
              "      <td>-1.827758</td>\n",
              "      <td>-0.151597</td>\n",
              "      <td>0.354927</td>\n",
              "      <td>0.410041</td>\n",
              "      <td>0.290936</td>\n",
              "      <td>1.486643</td>\n",
              "      <td>-0.961085</td>\n",
              "      <td>-2.082458</td>\n",
              "      <td>0.287470</td>\n",
              "      <td>-0.376133</td>\n",
              "      <td>-0.557385</td>\n",
              "      <td>-0.603392</td>\n",
              "      <td>0.823411</td>\n",
              "      <td>-1.134902</td>\n",
              "      <td>-0.813035</td>\n",
              "      <td>0.138361</td>\n",
              "      <td>-0.622539</td>\n",
              "      <td>-0.884037</td>\n",
              "      <td>0.589443</td>\n",
              "      <td>0.599244</td>\n",
              "      <td>-0.434928</td>\n",
              "      <td>-0.056931</td>\n",
              "      <td>0.386877</td>\n",
              "      <td>-1.304629</td>\n",
              "      <td>-0.071916</td>\n",
              "      <td>0.017805</td>\n",
              "      <td>1.067952</td>\n",
              "      <td>0.442997</td>\n",
              "      <td>-0.683415</td>\n",
              "      <td>0.290482</td>\n",
              "      <td>1.373441</td>\n",
              "      <td>-1.414913</td>\n",
              "      <td>0.884743</td>\n",
              "      <td>-1.262567</td>\n",
              "      <td>-0.289415</td>\n",
              "      <td>0.488108</td>\n",
              "      <td>...</td>\n",
              "      <td>1.120048</td>\n",
              "      <td>0.630364</td>\n",
              "      <td>0.122726</td>\n",
              "      <td>2.031761</td>\n",
              "      <td>-0.055893</td>\n",
              "      <td>1.448713</td>\n",
              "      <td>-0.204678</td>\n",
              "      <td>-1.870695</td>\n",
              "      <td>1.644773</td>\n",
              "      <td>-0.742985</td>\n",
              "      <td>-0.930501</td>\n",
              "      <td>-0.460158</td>\n",
              "      <td>0.054655</td>\n",
              "      <td>0.811828</td>\n",
              "      <td>-0.217333</td>\n",
              "      <td>0.674517</td>\n",
              "      <td>-1.108662</td>\n",
              "      <td>0.303383</td>\n",
              "      <td>-1.125366</td>\n",
              "      <td>-0.676069</td>\n",
              "      <td>-0.108096</td>\n",
              "      <td>0.499318</td>\n",
              "      <td>1.253587</td>\n",
              "      <td>0.262793</td>\n",
              "      <td>1.154885</td>\n",
              "      <td>1.690642</td>\n",
              "      <td>0.813351</td>\n",
              "      <td>0.820589</td>\n",
              "      <td>-0.642775</td>\n",
              "      <td>0.282380</td>\n",
              "      <td>0.149251</td>\n",
              "      <td>-0.265953</td>\n",
              "      <td>-0.056582</td>\n",
              "      <td>-0.476263</td>\n",
              "      <td>1.273418</td>\n",
              "      <td>-0.937739</td>\n",
              "      <td>-1.323298</td>\n",
              "      <td>0.769732</td>\n",
              "      <td>-0.485300</td>\n",
              "      <td>-0.568739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.666762</td>\n",
              "      <td>-0.143794</td>\n",
              "      <td>-0.442963</td>\n",
              "      <td>-0.576690</td>\n",
              "      <td>-1.275354</td>\n",
              "      <td>-0.998174</td>\n",
              "      <td>-0.146759</td>\n",
              "      <td>0.879924</td>\n",
              "      <td>1.341365</td>\n",
              "      <td>0.978886</td>\n",
              "      <td>-0.231094</td>\n",
              "      <td>-1.644314</td>\n",
              "      <td>-0.491945</td>\n",
              "      <td>0.215222</td>\n",
              "      <td>-0.486480</td>\n",
              "      <td>-1.106724</td>\n",
              "      <td>1.022923</td>\n",
              "      <td>-0.049618</td>\n",
              "      <td>-0.127286</td>\n",
              "      <td>0.517970</td>\n",
              "      <td>-0.734609</td>\n",
              "      <td>-0.998370</td>\n",
              "      <td>0.787060</td>\n",
              "      <td>1.272580</td>\n",
              "      <td>0.203808</td>\n",
              "      <td>-0.777243</td>\n",
              "      <td>-0.005262</td>\n",
              "      <td>-2.358310</td>\n",
              "      <td>-0.095952</td>\n",
              "      <td>0.381502</td>\n",
              "      <td>0.247634</td>\n",
              "      <td>0.224625</td>\n",
              "      <td>-0.227950</td>\n",
              "      <td>0.032097</td>\n",
              "      <td>0.795232</td>\n",
              "      <td>0.418362</td>\n",
              "      <td>0.278678</td>\n",
              "      <td>-0.541234</td>\n",
              "      <td>-0.791549</td>\n",
              "      <td>-0.088832</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227955</td>\n",
              "      <td>0.117184</td>\n",
              "      <td>0.058699</td>\n",
              "      <td>0.700803</td>\n",
              "      <td>-0.144747</td>\n",
              "      <td>1.083683</td>\n",
              "      <td>-1.126977</td>\n",
              "      <td>-1.867141</td>\n",
              "      <td>0.658834</td>\n",
              "      <td>-1.601521</td>\n",
              "      <td>0.135908</td>\n",
              "      <td>0.596416</td>\n",
              "      <td>-0.028338</td>\n",
              "      <td>-0.985066</td>\n",
              "      <td>0.402256</td>\n",
              "      <td>0.406297</td>\n",
              "      <td>0.277601</td>\n",
              "      <td>0.492491</td>\n",
              "      <td>0.411785</td>\n",
              "      <td>-0.148689</td>\n",
              "      <td>-0.476687</td>\n",
              "      <td>0.025912</td>\n",
              "      <td>0.311097</td>\n",
              "      <td>0.507197</td>\n",
              "      <td>0.201139</td>\n",
              "      <td>1.562022</td>\n",
              "      <td>1.125666</td>\n",
              "      <td>0.072363</td>\n",
              "      <td>-0.018190</td>\n",
              "      <td>0.685370</td>\n",
              "      <td>0.452535</td>\n",
              "      <td>-0.471679</td>\n",
              "      <td>-0.023094</td>\n",
              "      <td>-0.337895</td>\n",
              "      <td>0.363903</td>\n",
              "      <td>-0.307778</td>\n",
              "      <td>-0.617991</td>\n",
              "      <td>0.997004</td>\n",
              "      <td>-0.629949</td>\n",
              "      <td>-0.566559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.069362</td>\n",
              "      <td>-0.233245</td>\n",
              "      <td>-0.707548</td>\n",
              "      <td>-0.405131</td>\n",
              "      <td>-0.866063</td>\n",
              "      <td>0.839984</td>\n",
              "      <td>1.651828</td>\n",
              "      <td>0.202760</td>\n",
              "      <td>-0.172361</td>\n",
              "      <td>0.012175</td>\n",
              "      <td>0.314611</td>\n",
              "      <td>-0.378888</td>\n",
              "      <td>-1.195380</td>\n",
              "      <td>2.153757</td>\n",
              "      <td>0.776169</td>\n",
              "      <td>1.435112</td>\n",
              "      <td>0.446506</td>\n",
              "      <td>0.619781</td>\n",
              "      <td>0.202351</td>\n",
              "      <td>0.837998</td>\n",
              "      <td>-1.247207</td>\n",
              "      <td>-1.373395</td>\n",
              "      <td>0.200648</td>\n",
              "      <td>-1.422069</td>\n",
              "      <td>-0.544383</td>\n",
              "      <td>0.661354</td>\n",
              "      <td>1.316703</td>\n",
              "      <td>-0.681727</td>\n",
              "      <td>0.473052</td>\n",
              "      <td>-0.495689</td>\n",
              "      <td>1.304235</td>\n",
              "      <td>-1.088760</td>\n",
              "      <td>-0.257970</td>\n",
              "      <td>-0.903322</td>\n",
              "      <td>-1.168772</td>\n",
              "      <td>1.285644</td>\n",
              "      <td>0.115640</td>\n",
              "      <td>0.490505</td>\n",
              "      <td>-0.476049</td>\n",
              "      <td>0.914780</td>\n",
              "      <td>...</td>\n",
              "      <td>0.525266</td>\n",
              "      <td>-1.179180</td>\n",
              "      <td>0.582951</td>\n",
              "      <td>-1.695184</td>\n",
              "      <td>-0.632616</td>\n",
              "      <td>2.306023</td>\n",
              "      <td>2.140273</td>\n",
              "      <td>1.473589</td>\n",
              "      <td>-1.012092</td>\n",
              "      <td>0.353060</td>\n",
              "      <td>-1.457367</td>\n",
              "      <td>1.477214</td>\n",
              "      <td>-0.500333</td>\n",
              "      <td>0.937077</td>\n",
              "      <td>1.073265</td>\n",
              "      <td>1.860083</td>\n",
              "      <td>0.544829</td>\n",
              "      <td>-0.845580</td>\n",
              "      <td>1.275040</td>\n",
              "      <td>-0.099287</td>\n",
              "      <td>-1.041283</td>\n",
              "      <td>0.112604</td>\n",
              "      <td>0.885988</td>\n",
              "      <td>0.506146</td>\n",
              "      <td>-0.386344</td>\n",
              "      <td>0.706634</td>\n",
              "      <td>0.598918</td>\n",
              "      <td>0.722697</td>\n",
              "      <td>1.182420</td>\n",
              "      <td>1.124700</td>\n",
              "      <td>0.792663</td>\n",
              "      <td>-1.249455</td>\n",
              "      <td>-0.581341</td>\n",
              "      <td>-1.374341</td>\n",
              "      <td>0.337161</td>\n",
              "      <td>-0.357903</td>\n",
              "      <td>-0.434465</td>\n",
              "      <td>0.016996</td>\n",
              "      <td>-0.042338</td>\n",
              "      <td>1.655730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.976323</td>\n",
              "      <td>-1.551348</td>\n",
              "      <td>-0.806916</td>\n",
              "      <td>0.091348</td>\n",
              "      <td>-0.281060</td>\n",
              "      <td>0.707184</td>\n",
              "      <td>1.612100</td>\n",
              "      <td>0.639998</td>\n",
              "      <td>1.892194</td>\n",
              "      <td>-2.855943</td>\n",
              "      <td>1.089907</td>\n",
              "      <td>0.698763</td>\n",
              "      <td>0.089840</td>\n",
              "      <td>0.616718</td>\n",
              "      <td>0.904314</td>\n",
              "      <td>-0.962115</td>\n",
              "      <td>0.796160</td>\n",
              "      <td>-1.540566</td>\n",
              "      <td>-0.951313</td>\n",
              "      <td>-1.512815</td>\n",
              "      <td>-2.225848</td>\n",
              "      <td>0.219198</td>\n",
              "      <td>1.527213</td>\n",
              "      <td>-1.101838</td>\n",
              "      <td>-0.542287</td>\n",
              "      <td>-1.723024</td>\n",
              "      <td>1.931434</td>\n",
              "      <td>0.070675</td>\n",
              "      <td>-1.436893</td>\n",
              "      <td>0.074469</td>\n",
              "      <td>-0.946199</td>\n",
              "      <td>0.288246</td>\n",
              "      <td>-0.193207</td>\n",
              "      <td>-2.502442</td>\n",
              "      <td>-0.868171</td>\n",
              "      <td>0.670265</td>\n",
              "      <td>-0.873386</td>\n",
              "      <td>0.041233</td>\n",
              "      <td>0.061845</td>\n",
              "      <td>0.397624</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.388051</td>\n",
              "      <td>0.258765</td>\n",
              "      <td>0.206220</td>\n",
              "      <td>1.019654</td>\n",
              "      <td>0.379899</td>\n",
              "      <td>0.216348</td>\n",
              "      <td>-0.527735</td>\n",
              "      <td>0.743787</td>\n",
              "      <td>0.146710</td>\n",
              "      <td>-1.255293</td>\n",
              "      <td>-0.048208</td>\n",
              "      <td>-1.226158</td>\n",
              "      <td>-1.530687</td>\n",
              "      <td>-1.510438</td>\n",
              "      <td>1.230017</td>\n",
              "      <td>-0.414763</td>\n",
              "      <td>-0.098846</td>\n",
              "      <td>0.218546</td>\n",
              "      <td>-0.880817</td>\n",
              "      <td>-0.287900</td>\n",
              "      <td>0.479283</td>\n",
              "      <td>-0.359908</td>\n",
              "      <td>0.209833</td>\n",
              "      <td>1.040364</td>\n",
              "      <td>-0.060657</td>\n",
              "      <td>1.645617</td>\n",
              "      <td>1.812268</td>\n",
              "      <td>-0.333812</td>\n",
              "      <td>1.613451</td>\n",
              "      <td>1.614318</td>\n",
              "      <td>-0.391445</td>\n",
              "      <td>-0.685564</td>\n",
              "      <td>-0.604894</td>\n",
              "      <td>1.555282</td>\n",
              "      <td>-1.473485</td>\n",
              "      <td>-0.965220</td>\n",
              "      <td>0.972768</td>\n",
              "      <td>0.143044</td>\n",
              "      <td>1.113312</td>\n",
              "      <td>-0.068937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.206243</td>\n",
              "      <td>0.055220</td>\n",
              "      <td>-0.024269</td>\n",
              "      <td>1.154566</td>\n",
              "      <td>0.384821</td>\n",
              "      <td>0.923375</td>\n",
              "      <td>0.542934</td>\n",
              "      <td>0.061543</td>\n",
              "      <td>0.978539</td>\n",
              "      <td>-2.532515</td>\n",
              "      <td>0.328963</td>\n",
              "      <td>-0.089059</td>\n",
              "      <td>-1.015339</td>\n",
              "      <td>-0.616124</td>\n",
              "      <td>-0.677737</td>\n",
              "      <td>0.332761</td>\n",
              "      <td>-0.410661</td>\n",
              "      <td>-1.283385</td>\n",
              "      <td>0.541153</td>\n",
              "      <td>-0.869652</td>\n",
              "      <td>-0.952599</td>\n",
              "      <td>0.342414</td>\n",
              "      <td>0.373662</td>\n",
              "      <td>-0.063580</td>\n",
              "      <td>0.430808</td>\n",
              "      <td>-1.422466</td>\n",
              "      <td>1.846456</td>\n",
              "      <td>1.273539</td>\n",
              "      <td>0.432351</td>\n",
              "      <td>1.459942</td>\n",
              "      <td>-0.417334</td>\n",
              "      <td>0.672892</td>\n",
              "      <td>-0.912072</td>\n",
              "      <td>-0.649610</td>\n",
              "      <td>-0.283379</td>\n",
              "      <td>0.199266</td>\n",
              "      <td>-1.628320</td>\n",
              "      <td>1.010332</td>\n",
              "      <td>0.823642</td>\n",
              "      <td>-0.885436</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.887001</td>\n",
              "      <td>0.765091</td>\n",
              "      <td>0.347362</td>\n",
              "      <td>-0.119907</td>\n",
              "      <td>1.155579</td>\n",
              "      <td>-0.634465</td>\n",
              "      <td>0.412195</td>\n",
              "      <td>1.427624</td>\n",
              "      <td>-0.324900</td>\n",
              "      <td>-0.801008</td>\n",
              "      <td>-0.512062</td>\n",
              "      <td>-0.765594</td>\n",
              "      <td>-0.033555</td>\n",
              "      <td>-0.194099</td>\n",
              "      <td>0.529777</td>\n",
              "      <td>1.102575</td>\n",
              "      <td>-0.289583</td>\n",
              "      <td>-0.467591</td>\n",
              "      <td>-0.388407</td>\n",
              "      <td>0.457916</td>\n",
              "      <td>-0.331597</td>\n",
              "      <td>0.318833</td>\n",
              "      <td>0.121515</td>\n",
              "      <td>0.215371</td>\n",
              "      <td>-0.086138</td>\n",
              "      <td>1.056007</td>\n",
              "      <td>0.904831</td>\n",
              "      <td>0.428567</td>\n",
              "      <td>1.165235</td>\n",
              "      <td>-0.155509</td>\n",
              "      <td>0.914150</td>\n",
              "      <td>-0.211434</td>\n",
              "      <td>0.433467</td>\n",
              "      <td>0.381900</td>\n",
              "      <td>-0.360295</td>\n",
              "      <td>0.397423</td>\n",
              "      <td>0.536779</td>\n",
              "      <td>0.193482</td>\n",
              "      <td>-0.254351</td>\n",
              "      <td>-0.236691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        97        98        99\n",
              "0  1.532842  0.140309 -0.333336  ...  0.769732 -0.485300 -0.568739\n",
              "1  0.666762 -0.143794 -0.442963  ...  0.997004 -0.629949 -0.566559\n",
              "2  1.069362 -0.233245 -0.707548  ...  0.016996 -0.042338  1.655730\n",
              "3 -0.976323 -1.551348 -0.806916  ...  0.143044  1.113312 -0.068937\n",
              "4 -1.206243  0.055220 -0.024269  ...  0.193482 -0.254351 -0.236691\n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}